apiVersion: ai.sap.com/v1alpha1
kind: ServingTemplate
metadata:
  name: invoice-serving-pipeline
  annotations:
    scenarios.ai.sap.com/name: "Blocked Invoice Classification"
    scenarios.ai.sap.com/description: "Serve a Hugging Face model for blocked invoice classification"

    executables.ai.sap.com/name: "invoiceclassifierserving"
    executables.ai.sap.com/description: "Serving for blocked invoice classifier"

    artifacts.ai.sap.com/invoiceclassifiermodel.kind: "model"
  labels:
    scenarios.ai.sap.com/id: "invoice-classification"
    ai.sap.com/version: "1.0"
spec:
  inputs:
    artifacts:
      - name: invoiceclassifiermodel
  template:
    apiVersion: "serving.kserve.io/v1beta1"
    metadata:
      annotations: |
        autoscaling.knative.dev/metric: concurrency
        autoscaling.knative.dev/target: 1
        autoscaling.knative.dev/targetBurstCapacity: 0
      labels: |
        ai.sap.com/resourcePlan: serve.s
    spec: |
      predictor:
      
        imagePullSecrets:
        - name: your-docker-registry-secret

        minReplicas: 1
        maxReplicas: 3  #how much to scale up
        containers:
        - name: kserve-container
          image: docker.io/itsmarlo/invoice-serve:latest
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 8080
              protocol: TCP

          env:
            # KServe storage-initializer will download the bound artifact to /mnt/models
            - name: STORAGE_URI
              value: "{{inputs.artifacts.invoiceclassifiermodel}}"
            # Your app reads from /mnt/models by default
            - name: MODEL_PATH
              value: "/mnt/models"
            - name: PORT
              value: "8080"
